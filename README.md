# Race-Strategy-AI-F1-NFS
AI agent for NFS Most Wanted using Deep RL (Soft Actor-Critic). Learns fastest lap times by self-driving at full speed, reading game memory via custom API, correcting mistakes, and improving performance using expert data, OpenAI Gym, PyTorch, and real-time game control.
This project implements an autonomous racing agent that learns optimal lap times in *Need for Speed: Most Wanted* using **Deep Reinforcement Learning (DRL)** inspired by Formula 1 race strategies.
The agent races automatically at full speed, learns from collisions and off-track mistakes, and iteratively improves lap times using advanced self-learning algorithms.

---

## ğŸš€ Key Features

- ğŸ§  **Reinforcement Learning** with Soft Actor-Critic (SAC)
- ğŸ® **Game memory hacking** using Cheat Engine & custom API
- ğŸ”„ **Real-time control** via virtual gamepad interface
- ğŸ“Š **Custom OpenAI Gym environment** for training
- ğŸ Learns from both **self-play & expert gameplay data**
- ğŸ“ˆ Progressive lap-time optimization

---

## ğŸ›  Tech Stack

- Python
- PyTorch
- OpenAI Gym
- Stable-Baselines3
- Soft Actor-Critic (SAC)
- Cheat Engine / Memory Hacking Tools
- Virtual Game Controller APIs

---

## ğŸ–¥ï¸ Setup Instructions

1ï¸âƒ£ Clone the repository:

```bash
git clone https://github.com/yourusername/F1-NFS-RaceStrategy-AI.git
cd F1-NFS-RaceStrategy-AI

2ï¸âƒ£ Create virtual environment:

python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

3ï¸âƒ£ Install dependencies:

pip install -r requirements.txt

4ï¸âƒ£ Install and configure Cheat Engine or MemExplorer to extract game memory addresses.

5ï¸âƒ£ Run training:

python train.py

ğŸ“Š Results
AI agent successfully achieves continuous lap time improvement

Demonstrates learning from self-driving errors, crashes, and off-track behavior

Competitively matches human lap times after sufficient training

ğŸ” Disclaimer
Game memory modification done purely for research purposes.

No commercial or multiplayer usage involved.

Please respect applicable terms of use when replicating.

ğŸ“© Contact
For collaboration or questions:
[Aravindan TM] â€”  [www.linkedin.com/in/aravindantm]

